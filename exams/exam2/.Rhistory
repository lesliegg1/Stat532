ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[1], " data")))
points(grid.max[1], grid.max[2], col="red", pch=16, cex=2)
loglik.fun <- function(m.pi, y.vec){
sum(lchoose(m.pi[1], y.vec)+y.vec*log(m.pi[2])+(m.pi[1]-y.vec)*log(1-m.pi[2]))
}
y2.data <- c(16, 18, 22, 25, 28)
m <- seq(28, 250, by=1)
pi <- seq(0.05, 0.9, length=length(m))
grid.vals <- expand.grid(m=m, pi=pi)
grid.vals <- as.matrix(grid.vals)
loglik.vals <- apply(grid.vals, 1, loglik.fun, y.vec=y2.data)
lik.vals <- exp(loglik.vals-max(loglik.vals))
lik.mat <- matrix(lik.vals, nrow=length(m), ncol=length(pi))
#find where max occurs on grid
grid.max <- grid.vals[which(loglik.vals==max(loglik.vals)),]
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230),
ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[2], " data")))
points(grid.max[1], grid.max[2], col="red", pch=16, cex=2)
log.prior.fun <- function(m.pi) {
-lfactorial(m.pi[1])+m.pi[1]*log(100)-100
}
log.post.fun <- function(m.pi, y.vec) {
loglik.fun(m.pi, y.vec) + log.prior.fun(m.pi)
}
log.post.vals <- apply(grid.vals, 1, log.post.fun, y.vec=y2.data)
post.vals <- exp(log.post.vals-max(log.post.vals))
post.mat <- matrix(post.vals, nrow=length(m), ncol=length(pi))
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230), ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi), main="Posterior and Likelihood",
lwd=3, col="red")
contour(m, pi, post.mat, levels=seq(0.05, 0.95, 0.25), lwd=3, add=TRUE, col="black")
points(grid.max[1], grid.max[2], col="blue", pch=16, cex=2)
legend(150, 0.6, bty="n", legend=c("Likelihood", "Posterior"), lwd=c(3,3),
col=c("red", "black"), cex=1.1)
#function to calculate complete conditional for pi on log scale
log.pi.cc.fun <- function(m.pi, y.vec){
loglik.fun(m.pi, y.vec)
}
#check function
#log.pi.cc.fun(c(40, 0.5), y2.data)
#function to calculate complete conditional for m on log scale
log.m.cc.fun <- function(m.pi, y.vec){
log.post.fun(m.pi, y.vec)
}
#check function
#log.m.cc.fun(c(40, 0.5), y2.data)
nchain <- 3
nsim <- 10000
m.pi.mat <- array(NA, dim=c(nsim, 2, nchain))
#keep track of acceptance ratios
jump.mat <- matrix(NA, nrow=nsim-1, ncol=2)
#specify starting values for each chain
m.pi.mat[1, 1:2, 1] <- c(100, 0.4)
m.pi.mat[1, 1:2, 2] <- c(50, 0.2)
m.pi.mat[1, 1:2, 3] <- c(150, 0.4)
#define standard deviations for normal proposal distributions
sd.scale <- c(10, 5)
set.seed(230923)
for (j in 1:nchain) {
for (i in 2:nsim) {
#set pi equal to the starting value
pi <- m.pi.mat[i-1, 2, j]
#now draw m from complete conditional with Metropolis Hastings Algorithm
m.cur <- m.pi.mat[i-1, 1, j]
m.cand <- rpois(1, lambda=m.cur)
log.r.num.m <- log.m.cc.fun(c(m.cand, pi), y.vec = y2.data) +
dpois(m.cur, lambda=m.cand, log = TRUE)
log.r.denom.m <- log.m.cc.fun(c(m.cur, pi), y.vec = y2.data) +
dpois(m.cand, lambda=m.cur, log = TRUE)
log.r.m <- log.r.num.m - log.r.denom.m
p.accept.m <- min(1, exp(log.r.m))
u.vec <- runif(2)
ifelse(u.vec[1] <= p.accept.m, m.pi.mat[i, 1, j] <- m.cand,
m.pi.mat[i, 1, j] <- m.cur)
jump.mat[i-1, 1] <- ifelse(u.vec[1] <= p.accept.m, 1, 0)
#now fix m at its value in the ith iteration
m <- m.pi.mat[i, 1, j]
#draw pi from complete conditional with metropolis hastings algorithm
pi.cur <- m.pi.mat[i-1, 2, j]
pi.cand <- rbeta(1, 2, sd.scale[2])
log.r.num.pi <- log.pi.cc.fun(c(m, pi.cand), y.vec = y2.data) +
dbeta(pi.cur, 2, sd.scale[2], log = TRUE)
log.r.denom.pi <- log.pi.cc.fun(c(m, pi.cur), y.vec = y2.data) +
dbeta(pi.cand, 2, sd.scale[2], log = TRUE)
log.r.pi <- log.r.num.pi - log.r.denom.pi
p.accept.pi <- min(1, exp(log.r.pi))
u.vec <- runif(2)
ifelse(u.vec[2] <= p.accept.pi, m.pi.mat[i, 2, j] <- pi.cand,
m.pi.mat[i, 2, j] <- pi.cur)
jump.mat[i-1, 2] <- ifelse(u.vec[2] <= p.accept.pi, 1, 0)
}
}
plot(seq(1:nsim), m.pi.mat[1:nsim, 1, 1], type="l", ylab=expression(m))
lines(seq(1:nsim), m.pi.mat[1:nsim, 1, 2], col=2)
lines(seq(1:nsim), m.pi.mat[1:nsim, 1, 3], col=3)
plot(seq(1:nsim), m.pi.mat[1:nsim, 2, 1], type="l", ylab=expression(pi))
lines(seq(1:nsim), m.pi.mat[1:nsim, 2, 2], col=2)
lines(seq(1:nsim), m.pi.mat[1:nsim, 2, 3], col=3)
burnin <- 1000
require(coda)
m.post1 <- mcmc(m.pi.mat[burnin:nsim,1,1])
m.post2 <- mcmc(m.pi.mat[burnin:nsim,1,2])
m.post3 <- mcmc(m.pi.mat[burnin:nsim,1,3])
m.mcmc <- mcmc.list(list(m.post1, m.post2, m.post3))
eff <- effectiveSize(m.mcmc)
gelman.diag(m.mcmc)
pi.post1 <- mcmc(m.pi.mat[burnin:nsim,2,1])
pi.post2 <- mcmc(m.pi.mat[burnin:nsim,2,2])
pi.post3 <- mcmc(m.pi.mat[burnin:nsim,2,3])
pi.mcmc <- mcmc.list(list(pi.post1, pi.post2, pi.post3))
eff <- effectiveSize(pi.mcmc)
gelman.diag(pi.mcmc)
par(mfrow=c(1,2))
#plot draws
m.draws <- as.matrix(m.pi.mat[burnin:nsim, 1, ])
hist(m.draws, freq=FALSE, nclass=50, xlab=expression(m))
pi.draws <- as.matrix(m.pi.mat[burnin:nsim, 2, ])
hist(pi.draws, freq=FALSE, nclass=50, xlab=expression(pi))
#mean(m.draws>100)
#mean(pi.draws<0.3)
mean(m.draws)
mean(pi.draws)
loglik.fun <- function(m.pi, y.vec){
sum(lchoose(m.pi[1], y.vec)+y.vec*log(m.pi[2])+(m.pi[1]-y.vec)*log(1-m.pi[2]))
}
y2.data <- c(16, 18, 22, 25, 28)
m <- seq(28, 250, by=1)
pi <- seq(0.05, 0.9, length=length(m))
grid.vals <- expand.grid(m=m, pi=pi)
grid.vals <- as.matrix(grid.vals)
loglik.vals <- apply(grid.vals, 1, loglik.fun, y.vec=y2.data)
lik.vals <- exp(loglik.vals-max(loglik.vals))
lik.mat <- matrix(lik.vals, nrow=length(m), ncol=length(pi))
#find where max occurs on grid
grid.max <- grid.vals[which(loglik.vals==max(loglik.vals)),]
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230),
ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[2], " data")))
points(grid.max[1], grid.max[2], col="red", pch=16, cex=2)
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230),
ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[2], " data")))
points(mean(m.draws), mean(pi.draws), col="purpl", pch=16, cex=2)
points(grid.max[1], grid.max[2], col="purple", pch=16, cex=2)
points(mean(m.draws), mean(pi.draws), col="purple", pch=16, cex=2)
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230),
ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[2], " data")))
points(grid.max[1], grid.max[2], col="purple", pch=16, cex=2)
points(mean(m.draws), mean(pi.draws), col="red", pch=16, cex=2)
points(100, 0.5, col="green", pch=16, cex=0.2)
points(100, 0.5, col="green", pch=16, cex=2)
legend(120, 0.5, c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"))
legend(120, 0.5, c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"), pch=c(16, 16, 16))
legend(120, 0.5, bty="n", c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"), pch=c(16, 16, 16))
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230),
ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[2], " data")))
points(grid.max[1], grid.max[2], col="purple", pch=16, cex=2)
points(mean(m.draws), mean(pi.draws), col="red", pch=16, cex=2)
points(100, 0.5, col="green", pch=16, cex=2)
legend(120, 0.7, bty="n", c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"), pch=c(16, 16, 16))
grid.max
legend(130, 0.7, bty="n", c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"), pch=c(16, 16, 16), cex=0.8, lwd=c(2,2,2))
legend(130, 0.7, bty="n", c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"), pch=c(16, 16, 16), cex = c(2,2,2), cex=0.8)
contour(m, pi, lik.mat, levels=seq(0.05, 0.95, 0.25), xlim=c(20, 230),
ylim=c(0, 0.8),
xlab=expression(m), ylab=expression(pi),
main=expression(paste(y[2], " data")))
points(grid.max[1], grid.max[2], col="purple", pch=16, cex=2)
points(mean(m.draws), mean(pi.draws), col="red", pch=16, cex=2)
points(100, 0.5, col="green", pch=16, cex=2)
legend(130, 0.7, bty="n", c("Prior", "Posterior", "Likelihood"), col=c("green", "red", "purple"), pch=c(16, 16, 16), cex=0.8)
##write model file first
cat("
model
{
for(i in 1:N)
{
y[i] ~ dbin(pi, m)
}
pi ~ dbeta(eta/sigma^2, (1-eta)/sigma^2)
eta ~ dunif(0, 1)
sigma ~ dunif(0, 1)
m ~ dpois(lambda)
lambda ~ dunif(0, 500)
}",
file="model1.jags")
##jags call
library(R2jags)
set.seed(52)
dental.data <- list(N=length(y2.data), y=y2.data)
inits <- list(list(pi=0.4, eta = .00003, m = 100, lambda = 500,
sigma = 1.20),
list(pi=0.2, eta = .00003, m = 50, lambda = 150,
sigma = 2.24),
list(pi=0.4, eta = .00003, m = 150, lambda = 300,
sigma = 1.58))
n.chain <- 3
#warmup
warmup.model1 <- jags.model("model1.jags", data=dental.data, n.chains=n.chain, inits= inits, n.adapt=4000, quiet=TRUE)
#parameters to save
params <- c("pi", "eta", "sigma", "m", "lambda")
n.iter=50000
#running the model for real
model1 <- coda.samples(warmup.model1, params, n.iter=n.iter)
##jags call
library(R2jags)
set.seed(52)
dental.data <- list(N=length(y2.data), y=y2.data)
inits <- list(list(pi=0.4, eta = .00003, m = 100, lambda = 500,
sigma = 0.5),
list(pi=0.2, eta = .02, m = 50, lambda = 150,
sigma = 0.9),
list(pi=0.4, eta = .5, m = 150, lambda = 300,
sigma = 0.1))
n.chain <- 3
#warmup
warmup.model1 <- jags.model("model1.jags", data=dental.data, n.chains=n.chain, inits= inits, n.adapt=4000, quiet=TRUE)
#parameters to save
params <- c("pi", "eta", "sigma", "m", "lambda")
n.iter=50000
#running the model for real
model1 <- coda.samples(warmup.model1, params, n.iter=n.iter)
par(mfrow=c(2,3))
traceplot(model1)
gelman.diag(model1)
#par(mfrow=c(2,3))
#traceplot(model1)
m.jags.draws <- as.matrix(model1)[,3]
pi.jags.draws <- as.matrix(model1)[,4]
par(mfrow=c(1,2))
hist(m.jags.draws, freq=FALSE, nclass=40, xlab=expression(m), ylim=c(0, 0.04), main="m", col="lightgreen")
hist(m.draws, freq=FALSE, nclass=50, add=TRUE)
legend(120, 0.03, bty="n", c("Fixed hyperparams", "Hierarchical"), fill=c("white", "lightgreen"), cex=0.8)
hist(pi.jags.draws, freq=FALSE, nclass=30, xlab=expression(pi), main=expression(pi), ylim=c(0, 16), col="lightgreen")
hist(pi.draws, freq=FALSE, nclass=50, add=TRUE)
legend(0.25, 10, bty="n", c("Fixed hyperparams", "Hierarchical"), fill=c("white", "lightgreen"), cex=0.8)
set.seed(908)
pi.draw <- numeric(1000)
mu.draw <- numeric(1000)
lambda.draw <- numeric(1000)
for(i in 1:1000){
lambda.draw[i] <- runif(1, 0, 500)
m.draw <- rpois(1, lambda.draw)
sigma.draw <- runif(1, 0, 1)
eta.draw <- runif(1, 0, 1)
pi.draw[i] <- rbeta(1, eta.draw/sigma.draw^2, (1-eta.draw)/sigma.draw^2)
}
lambda.vals <- seq(0, 100, length=1000)
pi.vals <- seq(0, 1, length=1000)
mu.vals <- lambda.vals*pi.vals
mu.pi.vals <- expand.grid(mu.vals, pi.vals)
mu.pi.vals <- as.matrix(mu.pi.vals)
prior.vals.fun <- function(mu.pi){
1/mu.pi[1]
}
prior.vals <- apply(mu.pi.vals, 1, prior.vals.fun)
prior.mat <- matrix(prior.vals, nrow=length(mu.vals), ncol=length(pi.vals))
contour(lambda.vals, pi.vals, prior.mat, levels=seq(0.05, 0.95, 0.25),
xlab=expression(lambda), ylab=expression(pi), main="Raftery Prior vs. Prior (i)",
lwd=3, col="red", xlim = c(0, 500))
points(lambda.draw, pi.draw, col="black", pch=16)
legend(20, 0.6, bty="n", legend=c("Raftery Prior", "Prior (i)"),
fill=c("red", "black"), cex=0.8)
#par(mfrow=c(2,3))
#traceplot(model1)
m.jags.draws <- as.matrix(model1)[,3]
pi.jags.draws <- as.matrix(model1)[,4]
par(mfrow=c(1,2))
hist(m.jags.draws, freq=FALSE, nclass=40, xlab=expression(m), ylim=c(0, 0.04), main="m", col="lightgreen")
hist(m.draws, freq=FALSE, nclass=50, add=TRUE)
legend(120, 0.03, bty="n", c("Fixed hyperparams", "Hierarchical"), fill=c("white", "lightgreen"), cex=0.8)
hist(pi.jags.draws, freq=FALSE, nclass=30, xlab=expression(pi), main=expression(pi), ylim=c(0, 16), col="lightgreen")
hist(pi.draws, freq=FALSE, nclass=50, add=TRUE)
legend(0.25, 10, bty="n", c("Fixed hyperparams", "Hierarchical"), fill=c("white", "lightgreen"), cex=0.8)
par(mfrow=c(1,3))
lambda.draws <- as.matrix(model1)[,2]
sigma.draws <- as.matrix(model1)[,5]
eta.draws <- as.matrix(model1)[,1]
hist(lambda.draws, main=expression(lambda), freq=FALSE, xlab=expression(lambda))
abline(v=100, lwd=3, col="red")
hist(sigma.draws, main=expression(sigma), freq=FALSE, xlab=expression(sigma))
abline(v=0.707, lwd=3, col="red")
hist(eta.draws, main=expression(eta), freq=FALSE, xlab=expression(eta))
abline(v=0.5, lwd=3, col="red")
set.seed(908)
pi.draw <- numeric(1000)
mu.draw <- numeric(1000)
lambda.draw <- numeric(1000)
for(i in 1:1000){
lambda.draw[i] <- runif(1, 0, 500)
m.draw <- rpois(1, lambda.draw)
sigma.draw <- runif(1, 0, 1)
eta.draw <- runif(1, 0, 1)
pi.draw[i] <- rbeta(1, eta.draw/sigma.draw^2, (1-eta.draw)/sigma.draw^2)
}
lambda.vals <- seq(0, 100, length=1000)
pi.vals <- seq(0, 1, length=1000)
mu.vals <- lambda.vals*pi.vals
mu.pi.vals <- expand.grid(mu.vals, pi.vals)
mu.pi.vals <- as.matrix(mu.pi.vals)
prior.vals.fun <- function(mu.pi){
1/mu.pi[1]
}
prior.vals <- apply(mu.pi.vals, 1, prior.vals.fun)
prior.mat <- matrix(prior.vals, nrow=length(mu.vals), ncol=length(pi.vals))
contour(lambda.vals, pi.vals, prior.mat, levels=seq(0.05, 0.95, 0.25),
xlab=expression(lambda), ylab=expression(pi), main="Raftery Prior vs. Prior (i)",
lwd=3, col="red", xlim = c(0, 500))
points(lambda.draw, pi.draw, col="lightgrey", pch=16)
legend(20, 0.6, bty="n", legend=c("Raftery Prior", "Prior (i)"),
fill=c("red", "lightgrey"), cex=0.8)
set.seed(908)
pi.draw <- numeric(1000)
mu.draw <- numeric(1000)
lambda.draw <- numeric(1000)
for(i in 1:1000){
lambda.draw[i] <- runif(1, 0, 500)
m.draw <- rpois(1, lambda.draw)
sigma.draw <- runif(1, 0, 1)
eta.draw <- runif(1, 0, 1)
pi.draw[i] <- rbeta(1, eta.draw/sigma.draw^2, (1-eta.draw)/sigma.draw^2)
}
lambda.vals <- seq(0, 100, length=1000)
pi.vals <- seq(0, 1, length=1000)
mu.vals <- lambda.vals*pi.vals
mu.pi.vals <- expand.grid(mu.vals, pi.vals)
mu.pi.vals <- as.matrix(mu.pi.vals)
prior.vals.fun <- function(mu.pi){
1/mu.pi[1]
}
prior.vals <- apply(mu.pi.vals, 1, prior.vals.fun)
prior.mat <- matrix(prior.vals, nrow=length(mu.vals), ncol=length(pi.vals))
contour(lambda.vals, pi.vals, prior.mat, levels=seq(0.05, 0.95, 0.25),
xlab=expression(lambda), ylab=expression(pi), main="Raftery Prior vs. Prior (i)",
lwd=4, col="red", xlim = c(0, 500))
points(lambda.draw, pi.draw, col="lightgrey", pch=16)
legend(200, 0.6, bty="n", legend=c("Raftery Prior", "Prior (i)"),
fill=c("red", "lightgrey"), cex=1)
data {
int<lower=0> N;
vector[N] x;
int<lower=0,upper=1> y[N];
}
parameters {
real alpha;
real beta;
}
model {
y ~ bernoulli_logit(alpha + beta * x);
}
data {
int<lower=0> N;
vector[N] x;
int<lower=0,upper=1> y[N];
}
parameters {
real alpha;
real beta;
}
model {
y ~ bernoulli_logit(alpha + beta * x);
}
require(rstan)
set.seed(23)
data <- with(frog.data, list(y = death, x = dose, N = length(death)))
model2 <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2.stan",
model_name = "model2")
samp2 <- sampling(model2, chains = 4, iter = 50000, data = data)
setwd("~/Documents/Stat532/exams/exam2")
frog.data <- read.csv("FrogDoseData.csv")
set.seed(23)
data <- with(frog.data, list(y = death, x = dose, N = length(death)))
model2 <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2.stan",
model_name = "model2")
samp2 <- sampling(model2, chains = 4, iter = 50000, data = data)
model2 <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2.stan",
model_name = "model2")
samp2 <- sampling(model2, chains = 4, iter = 10000, data = data)
traceplot(samp2)
par(mfrow=c(1,2))
require(rstan)
alpha.bad <- extract(samp2)$alpha
hist(alpha.bad, freq = F, xlab=expression(alpha), nclass=30, main=expression(alpha))
abline(v=coefs[1], col="red", lwd=3)
beta.bad <- extract(samp2)$beta
hist(beta.bad, freq=F, xlab=expression(beta), nclass=30, main= expression(beta))
abline(v=coefs[2], col="red", lwd=3)
set.seed(58)
dose.standard <- with(frog.data, (dose - mean(dose))/sd(dose))
std.data <- with(frog.data, list(y = death, x = dose.standard, N = length(death)))
std.model2 <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2.stan",
model_name = "std.model2")
std.samp2 <- sampling(std.model2, chains = 4, iter = 2000, data = std.data)
require(rstan)
set.seed(232364)
data <- with(frog.data, list(y = death, x = dose, N = length(death)))
model2.cauchy <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2cauchy.stan",
model_name = "model2.cauchy")
alpha <- extract(samp2.cauchy)$alpha
data <- with(frog.data, list(y = death, x = dose, N = length(death)))
model2.cauchy <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2cauchy.stan",
model_name = "model2.cauchy")
samp2.cauchy <- sampling(model2.cauchy, chains = 4, iter = 2000, data = data)
par(mfrow=c(1,2))
require(rstan)
alpha <- extract(samp2.cauchy)$alpha
hist(alpha, freq = F, xlab=expression(alpha), nclass=30, main=expression(alpha))
abline(v=coefs[1], col="red", lwd=3)
beta <- extract(samp2.cauchy)$beta
hist(beta, freq=F, xlab=expression(beta), nclass=30, main= expression(beta))
abline(v=coefs[2], col="red", lwd=3)
mean(alpha)
mean(beta)
ld50 <- (0.5 - alpha)/beta
ld50.postmean <- mean(ld50)
ld50.postmean
ld50 <- (0.5 - alpha)/beta
ld50.postmean <- mean(ld50)
par(mfrow=c(1,2))
#logit plot
emp.logits <- logit(emp.probs)
x <- seq(0, 3, by = 0.01)
plot(x, alpha[1] + beta[1]*x, type= "l", col="lightgrey", xlab= "dose", ylab="logit(Pr(Death)", main="Fitted Logits", ylim=c(-50, 50))
for(i in 2:4000){
lines(x, alpha[i] + beta[i]*x, col="lightgrey")
}
abline(v = ld50.postmean, col="red", lwd=3)
points(unique(frog.data$dose), emp.logits, pch=15, cex=1.5)
#probability plot
dose1 <- with(frog.data, sum(death[dose==0.42])/5)
dose2 <- with(frog.data, sum(death[dose==0.71])/5)
dose3 <- with(frog.data, sum(death[dose==0.98])/5)
dose4 <- with(frog.data, sum(death[dose==2.13])/5)
emp.probs <-  c(dose1, dose2, dose3, dose4)
#fitted.probs <- fitted(glm.fit)
plot(frog.data$dose, fitted.probs, type="n", ylab="Pr(Death)", xlab="Dose",
main="Fitted Probabilities")
curve(invlogit(alpha[1] + beta[1]*x), lwd=1, col="lightgrey", add=TRUE)
for(i in 2:4000){
curve(invlogit(alpha[i] + beta[i]*x), col="lightgrey", add=TRUE)
}
curve(invlogit(coefs[1] + coefs[2]*x),
lwd=2, col=2, add=TRUE)
abline(v = ld50.postmean, col="red", lwd=3)
points(unique(frog.data$dose), emp.probs, pch=15, cex=1.5)
par(mfrow=c(1,2))
x <- seq(-30, 30, by=0.01)
plot(x, dcauchy(x, 0, 2), type="l", xlab="", main=expression(paste("Cauchy(0, 2) for ", alpha)), lwd=2, lty=2, xlim= c(-10, 10))
plot(x, dcauchy(x, 0, 2.5), type="l", xlab="", main=expression(paste("Folded Cauchy (0, 2.5) for ", beta)), lwd=2, lty=2, xlim= c(0, 30))
require(rstan)
set.seed(232364)
data <- with(frog.data, list(y = death, x = dose, N = length(death)))
model2.inform <- stan_model(file = "~/Documents/Stat532/exams/exam2/model2inform.stan",
model_name = "model2.inform")
samp2.inform <- sampling(model2.inform, chains = 4, iter = 2000, data = data)
par(mfrow=c(1,2))
require(rstan)
alpha.inform <- extract(samp2.inform)$alpha
hist(alpha.inform, freq = F, xlab=expression(alpha), nclass=30, main=expression(alpha))
abline(v=coefs[1], col="red", lwd=3)
beta.inform <- extract(samp2.inform)$beta
hist(beta.inform, freq=F, xlab=expression(beta), nclass=30, main= expression(beta))
abline(v=coefs[2], col="red", lwd=3)
glm.fit <- glm(death ~ dose, data = frog.data, family = "binomial")
require(arm)
dose1 <- with(frog.data, sum(death[dose==0.42])/5)
dose2 <- with(frog.data, sum(death[dose==0.71])/5)
dose3 <- with(frog.data, sum(death[dose==0.98])/5)
dose4 <- with(frog.data, sum(death[dose==2.13])/5)
emp.probs <-  c(dose1, dose2, dose3, dose4)
fitted.probs <- fitted(glm.fit)
plot(frog.data$dose, fitted.probs, type="n", ylab="Pr(Death)", xlab="Dose",
main="Fitted Probabilities")
coefs <- coef(glm.fit)
curve(invlogit(coefs[1] + coefs[2]*x),
lwd=2, col=2, add=TRUE)
points(unique(frog.data$dose), emp.probs, pch=15, cex=1.5)
par(mfrow=c(1,2))
require(rstan)
alpha.inform <- extract(samp2.inform)$alpha
hist(alpha.inform, freq = F, xlab=expression(alpha), nclass=30, main=expression(alpha))
abline(v=coefs[1], col="red", lwd=3)
beta.inform <- extract(samp2.inform)$beta
hist(beta.inform, freq=F, xlab=expression(beta), nclass=30, main= expression(beta))
abline(v=coefs[2], col="red", lwd=3)
mean(alpha.inform)
invlogit(-7.705764)
invlogit(quantile(alpha.inform, 0.025))
invlogit(quantile(alpha.inform, 0.975))
mean(beta.inform)
exp(9.95)
exp(9.95/10)
exp(quantile(beta.inform, 0.025))
exp(quantile(beta.inform, 0.025)/10)
exp(quantile(beta.inform, 0.975)/10)
ld50 <- (0.5 - alpha.inform)/beta.inform
ld50.postmean <- mean(ld50)
ld50.postmean
ld50.l <- quantile(ld50, 0.0275)
ld50.u <- quantile(ld50, 0.975)
ld50.l
ld50.u
